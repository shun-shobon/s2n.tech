---
title: Node.js Stream API完全ガイド - 大容量データを効率的に処理しよう
tags:
  - Node.js
  - Stream
  - Backend
  - Performance
publishedAt: "2023-07-05"
updatedAt: "2024-02-18"
---

## はじめに

Node.jsのStream APIは、大容量のデータを効率的に処理するための強力な機能です。
メモリ使用量を抑えながら、リアルタイムでデータの読み書きや変換ができます。
ファイル処理、HTTP通信、データ変換など、様々な場面で活用できます。
今回は、Stream APIの基本から実践的な使い方まで詳しく解説していきます。

## Streamの基本概念

### Streamの種類

Node.jsには4つの基本的なStreamタイプがあります：

```javascript
const { Readable, Writable, Transform, Duplex } = require("stream");

// 1. Readable Stream - データを読み取る
// 2. Writable Stream - データを書き込む
// 3. Transform Stream - データを変換する
// 4. Duplex Stream - 読み書き両方ができる
```

### Streamの利点

```javascript
// ❌ 従来の方法：全体をメモリに読み込む
const fs = require("fs");

// 大きなファイル（例：1GB）を一度にメモリに読み込む
fs.readFile("huge-file.txt", (err, data) => {
	if (err) throw err;
	console.log(data.length); // 1GBのデータがメモリに
});

// ✅ Stream：少しずつ処理
const readStream = fs.createReadStream("huge-file.txt");
readStream.on("data", (chunk) => {
	console.log(`受信したチャンク: ${chunk.length}bytes`);
	// メモリ使用量は常に一定
});
```

## Readable Stream

### 基本的な使い方

```javascript
const fs = require("fs");
const { pipeline } = require("stream/promises");

// ファイルからの読み取り
const readStream = fs.createReadStream("input.txt", {
	encoding: "utf8",
	highWaterMark: 16 * 1024, // 16KBずつ読み取り
});

readStream.on("data", (chunk) => {
	console.log("データを受信:", chunk.length);
});

readStream.on("end", () => {
	console.log("読み取り完了");
});

readStream.on("error", (err) => {
	console.error("エラー:", err);
});
```

### カスタムReadable Streamの作成

```javascript
const { Readable } = require("stream");

class NumberStream extends Readable {
	constructor(options) {
		super(options);
		this.current = 0;
		this.max = options.max || 100;
	}

	_read() {
		if (this.current < this.max) {
			this.push(`数値: ${this.current}\n`);
			this.current++;
		} else {
			// null をpushするとストリーム終了
			this.push(null);
		}
	}
}

// 使用例
const numberStream = new NumberStream({ max: 10 });
numberStream.on("data", (chunk) => {
	console.log(chunk.toString().trim());
});
```

### 非同期イテレータとの組み合わせ

```javascript
const fs = require("fs");

async function processFile() {
	const readStream = fs.createReadStream("large-file.txt", {
		encoding: "utf8",
	});

	try {
		for await (const chunk of readStream) {
			// 各チャンクを非同期で処理
			await processChunk(chunk);
		}
		console.log("処理完了");
	} catch (error) {
		console.error("処理エラー:", error);
	}
}

async function processChunk(chunk) {
	// 何らかの非同期処理
	return new Promise((resolve) => {
		setTimeout(() => {
			console.log(`処理したチャンク: ${chunk.length}文字`);
			resolve();
		}, 100);
	});
}
```

## Writable Stream

### 基本的な使い方

```javascript
const fs = require("fs");

const writeStream = fs.createWriteStream("output.txt", {
	encoding: "utf8",
});

// データの書き込み
writeStream.write("最初の行\n");
writeStream.write("2番目の行\n");
writeStream.write("3番目の行\n");

// ストリームを終了
writeStream.end("最後の行\n");

writeStream.on("finish", () => {
	console.log("書き込み完了");
});

writeStream.on("error", (err) => {
	console.error("書き込みエラー:", err);
});
```

### カスタムWritable Streamの作成

```javascript
const { Writable } = require("stream");

class UpperCaseWriteStream extends Writable {
	constructor(options) {
		super(options);
	}

	_write(chunk, encoding, callback) {
		// データを大文字に変換して出力
		const upperChunk = chunk.toString().toUpperCase();
		process.stdout.write(upperChunk);
		callback();
	}
}

// 使用例
const upperWriter = new UpperCaseWriteStream();
upperWriter.write("hello world\n");
upperWriter.write("node.js streams\n");
upperWriter.end();
```

### バックプレッシャーの処理

```javascript
const fs = require("fs");

const writeStream = fs.createWriteStream("output.txt");

function writeMillionTimes(writer, data, encoding, callback) {
	let i = 1000000;

	function write() {
		let ok = true;
		while (i > 0 && ok) {
			i--;
			if (i === 0) {
				// 最後のwrite
				writer.write(data, encoding, callback);
			} else {
				ok = writer.write(data, encoding);
			}
		}

		if (i > 0) {
			// バックプレッシャーが発生、drainイベントを待つ
			writer.once("drain", write);
		}
	}

	write();
}

writeMillionTimes(writeStream, "データ\n", "utf8", () => {
	console.log("100万回の書き込み完了");
	writeStream.end();
});
```

## Transform Stream

### 基本的な変換

```javascript
const { Transform } = require("stream");

class ReverseTransform extends Transform {
	_transform(chunk, encoding, callback) {
		// 各行を逆順にする
		const reversed = chunk
			.toString()
			.split("\n")
			.map((line) => line.split("").reverse().join(""))
			.join("\n");

		callback(null, reversed);
	}
}

// 使用例
const fs = require("fs");
const reverseTransform = new ReverseTransform();

fs.createReadStream("input.txt")
	.pipe(reverseTransform)
	.pipe(fs.createWriteStream("output.txt"));
```

### JSON処理のためのTransform

```javascript
const { Transform } = require("stream");

class JSONLineTransform extends Transform {
	constructor(options) {
		super({ objectMode: true, ...options });
	}

	_transform(chunk, encoding, callback) {
		const lines = chunk.toString().split("\n");

		for (const line of lines) {
			if (line.trim()) {
				try {
					const jsonObj = JSON.parse(line);
					this.push(jsonObj);
				} catch (err) {
					this.emit("error", new Error(`無効なJSON: ${line}`));
					return;
				}
			}
		}

		callback();
	}
}

// 使用例
const jsonTransform = new JSONLineTransform();

jsonTransform.on("data", (obj) => {
	console.log("パースされたオブジェクト:", obj);
});

jsonTransform.write('{"name": "Alice", "age": 30}\n');
jsonTransform.write('{"name": "Bob", "age": 25}\n');
jsonTransform.end();
```

### CSVパーサーの実装

```javascript
const { Transform } = require("stream");

class CSVTransform extends Transform {
	constructor(options = {}) {
		super({ objectMode: true });
		this.headers = options.headers || null;
		this.separator = options.separator || ",";
		this.buffer = "";
	}

	_transform(chunk, encoding, callback) {
		this.buffer += chunk.toString();
		const lines = this.buffer.split("\n");

		// 最後の（不完全かもしれない）行をバッファに戻す
		this.buffer = lines.pop();

		for (const line of lines) {
			if (line.trim()) {
				const values = line.split(this.separator);

				if (!this.headers) {
					this.headers = values;
				} else {
					const obj = {};
					this.headers.forEach((header, index) => {
						obj[header.trim()] = values[index]?.trim() || "";
					});
					this.push(obj);
				}
			}
		}

		callback();
	}

	_flush(callback) {
		if (this.buffer.trim() && this.headers) {
			const values = this.buffer.split(this.separator);
			const obj = {};
			this.headers.forEach((header, index) => {
				obj[header.trim()] = values[index]?.trim() || "";
			});
			this.push(obj);
		}
		callback();
	}
}

// 使用例
const csvTransform = new CSVTransform();

csvTransform.on("data", (row) => {
	console.log("行データ:", row);
});

csvTransform.write("name,age,city\n");
csvTransform.write("Alice,30,Tokyo\n");
csvTransform.write("Bob,25,Osaka\n");
csvTransform.end();
```

## Pipeline と Composition

### pipeline() 関数の使用

```javascript
const { pipeline } = require("stream/promises");
const fs = require("fs");
const zlib = require("zlib");

async function compressFile() {
	try {
		await pipeline(
			fs.createReadStream("input.txt"),
			zlib.createGzip(),
			fs.createWriteStream("output.txt.gz"),
		);
		console.log("圧縮完了");
	} catch (error) {
		console.error("パイプラインエラー:", error);
	}
}

compressFile();
```

### 複数のTransformを組み合わせ

```javascript
const { pipeline } = require("stream/promises");
const { Transform } = require("stream");
const fs = require("fs");

// 行番号を追加するTransform
class LineNumberTransform extends Transform {
	constructor() {
		super();
		this.lineNumber = 1;
	}

	_transform(chunk, encoding, callback) {
		const lines = chunk.toString().split("\n");
		const numberedLines = lines.map((line, index) => {
			if (index === lines.length - 1 && line === "") return line;
			return `${this.lineNumber++}: ${line}`;
		});
		callback(null, numberedLines.join("\n"));
	}
}

// 大文字変換Transform
class UpperCaseTransform extends Transform {
	_transform(chunk, encoding, callback) {
		callback(null, chunk.toString().toUpperCase());
	}
}

async function processFile() {
	try {
		await pipeline(
			fs.createReadStream("input.txt"),
			new LineNumberTransform(),
			new UpperCaseTransform(),
			fs.createWriteStream("output.txt"),
		);
		console.log("ファイル処理完了");
	} catch (error) {
		console.error("処理エラー:", error);
	}
}
```

## HTTP Streamingの実践

### サーバーサイドでのStreaming

```javascript
const http = require("http");
const fs = require("fs");
const { pipeline } = require("stream/promises");

const server = http.createServer(async (req, res) => {
	if (req.method === "GET" && req.url === "/download") {
		// 大容量ファイルのストリーミング配信
		res.setHeader("Content-Type", "application/octet-stream");
		res.setHeader(
			"Content-Disposition",
			'attachment; filename="large-file.txt"',
		);

		try {
			await pipeline(fs.createReadStream("large-file.txt"), res);
		} catch (error) {
			console.error("ストリーミングエラー:", error);
			if (!res.headersSent) {
				res.statusCode = 500;
				res.end("Internal Server Error");
			}
		}
	} else if (req.method === "POST" && req.url === "/upload") {
		// ファイルアップロードの受信
		try {
			await pipeline(req, fs.createWriteStream("uploaded-file.txt"));
			res.end("Upload complete");
		} catch (error) {
			console.error("アップロードエラー:", error);
			res.statusCode = 500;
			res.end("Upload failed");
		}
	} else {
		res.statusCode = 404;
		res.end("Not Found");
	}
});

server.listen(3000, () => {
	console.log("サーバーが起動しました: http://localhost:3000");
});
```

### リアルタイムデータ配信

```javascript
const http = require("http");
const { Readable } = require("stream");

class RealTimeDataStream extends Readable {
	constructor(options) {
		super(options);
		this.interval = setInterval(() => {
			const data = {
				timestamp: new Date().toISOString(),
				value: Math.random() * 100,
				id: Math.random().toString(36).substr(2, 9),
			};

			this.push(`data: ${JSON.stringify(data)}\n\n`);
		}, 1000);
	}

	_read() {
		// 何もしない（setIntervalでデータをpush）
	}

	_destroy() {
		clearInterval(this.interval);
	}
}

const server = http.createServer((req, res) => {
	if (req.url === "/stream") {
		res.writeHead(200, {
			"Content-Type": "text/plain",
			"Cache-Control": "no-cache",
			"Connection": "keep-alive",
			"Access-Control-Allow-Origin": "*",
		});

		const dataStream = new RealTimeDataStream();
		dataStream.pipe(res);

		req.on("close", () => {
			dataStream.destroy();
		});
	} else {
		res.statusCode = 404;
		res.end("Not Found");
	}
});

server.listen(3000);
```

## パフォーマンス最適化

### バッファサイズの調整

```javascript
const fs = require("fs");

// 小さなファイル：小さなバッファ
const smallFileStream = fs.createReadStream("small.txt", {
	highWaterMark: 4 * 1024, // 4KB
});

// 大きなファイル：大きなバッファ
const largeFileStream = fs.createReadStream("large.txt", {
	highWaterMark: 64 * 1024, // 64KB
});

// バッファサイズの測定
function measureThroughput(stream, name) {
	let totalBytes = 0;
	let chunkCount = 0;
	const startTime = Date.now();

	stream.on("data", (chunk) => {
		totalBytes += chunk.length;
		chunkCount++;
	});

	stream.on("end", () => {
		const duration = Date.now() - startTime;
		console.log(`${name}:`);
		console.log(`  総サイズ: ${totalBytes} bytes`);
		console.log(`  チャンク数: ${chunkCount}`);
		console.log(`  処理時間: ${duration} ms`);
		console.log(
			`  スループット: ${(((totalBytes / duration) * 1000) / 1024 / 1024).toFixed(2)} MB/s`,
		);
	});
}
```

### 並列処理の実装

```javascript
const { Worker } = require("worker_threads");
const { Transform } = require("stream");

class ParallelTransform extends Transform {
	constructor(workerScript, options = {}) {
		super({ objectMode: true });
		this.workerScript = workerScript;
		this.concurrency = options.concurrency || 4;
		this.workers = [];
		this.queue = [];
		this.processing = 0;

		// ワーカーの初期化
		for (let i = 0; i < this.concurrency; i++) {
			this.createWorker();
		}
	}

	createWorker() {
		const worker = new Worker(this.workerScript);
		worker.available = true;
		this.workers.push(worker);

		worker.on("message", (result) => {
			worker.available = true;
			this.processing--;
			this.push(result);
			this.processQueue();
		});
	}

	_transform(chunk, encoding, callback) {
		this.queue.push({ chunk, callback });
		this.processQueue();
	}

	processQueue() {
		while (this.queue.length > 0 && this.processing < this.concurrency) {
			const availableWorker = this.workers.find((w) => w.available);
			if (!availableWorker) break;

			const { chunk, callback } = this.queue.shift();
			availableWorker.available = false;
			this.processing++;
			availableWorker.postMessage(chunk);
			callback();
		}
	}

	_flush(callback) {
		// すべての処理が完了するまで待機
		const checkComplete = () => {
			if (this.processing === 0 && this.queue.length === 0) {
				this.workers.forEach((worker) => worker.terminate());
				callback();
			} else {
				setTimeout(checkComplete, 10);
			}
		};
		checkComplete();
	}
}
```

## エラーハンドリングとデバッグ

### エラー処理のベストプラクティス

```javascript
const { pipeline } = require("stream/promises");
const { Transform } = require("stream");

class SafeTransform extends Transform {
	_transform(chunk, encoding, callback) {
		try {
			// 危険な処理
			const result = this.processDangerousData(chunk);
			callback(null, result);
		} catch (error) {
			// エラーを適切に処理
			this.emit("error", error);
		}
	}

	processDangerousData(chunk) {
		// 何らかの危険な処理
		const data = JSON.parse(chunk.toString());
		return JSON.stringify(data.result);
	}
}

async function robustPipeline() {
	try {
		await pipeline(sourceStream, new SafeTransform(), destinationStream);
	} catch (error) {
		console.error("パイプラインでエラーが発生:", error);
		// クリーンアップ処理
		await cleanup();
	}
}
```

### ストリームの監視

```javascript
function monitorStream(stream, name) {
	let bytesProcessed = 0;
	let chunksProcessed = 0;

	stream.on("data", (chunk) => {
		bytesProcessed += chunk.length;
		chunksProcessed++;

		if (chunksProcessed % 100 === 0) {
			console.log(
				`${name}: ${chunksProcessed} chunks, ${bytesProcessed} bytes`,
			);
		}
	});

	stream.on("end", () => {
		console.log(
			`${name} 完了: ${chunksProcessed} chunks, ${bytesProcessed} bytes`,
		);
	});

	stream.on("error", (err) => {
		console.error(`${name} エラー:`, err);
	});

	return stream;
}

// 使用例
const monitoredStream = monitorStream(
	fs.createReadStream("file.txt"),
	"FileReader",
);
```

## 終わりに

Node.js Streamを使うことで：

1. **メモリ効率**: 大容量データも少ないメモリで処理
2. **リアルタイム処理**: データが到着次第すぐに処理開始
3. **組み合わせ可能**: パイプラインで複数の処理を連結
4. **スケーラビリティ**: バックプレッシャーによる自動的な流量制御

Streamは最初は複雑に感じるかもしれませんが、大容量データやリアルタイム処理には欠かせない技術です。
少しずつ慣れていって、効率的なNode.jsアプリケーションを構築していきましょう！
